{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gandesirijugalkishore/DATA-MIGRATION/blob/main/DATA_FROM_TO_ELASTIC_SEARCH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tC5Gp3HlXn5i"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import IntegerType, DateType, StringType\n",
        "from pyspark.sql.functions import col, unix_timestamp\n",
        "from pyspark.sql import functions as sf\n",
        "import time\n",
        "import yaml\n",
        "import pickle\n",
        "from datetime import datetime, date, timedelta\n",
        "from elasticsearch import Elasticsearch\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def createSparkSession():\n",
        "    spark_session = SparkSession.builder.appName(\"app\").getOrCreate()\n",
        "    return spark_session\n",
        "\n",
        "\n",
        "def readFromElasticSearch(spark,index):\n",
        "    df= spark.read\\\n",
        "    .format(\"org.elasticsearch.spark.sql\")\\\n",
        "    .option(\"es.nodes\",\"..........\")\\\n",
        "    .load(index)\n",
        "    return df.limit(100)\n",
        "\n",
        "def writeToElasticSearch(df,es_config):\n",
        "    es_host = f\"http://{es_config['host']}:{es_config['port']}\"\n",
        "    es_user = es_config['username']\n",
        "    es_pass = es_config['password']\n",
        "    index_name = es_config['index_name']\n",
        "    print(f'Index name : {index_name}')\n",
        "    df.write.format(\"org.elasticsearch.spark.sql\").option(\"es.nodes\", es_host)\\\n",
        "                                                    .option(\"es.net.http.auth.user\",es_user) \\\n",
        "                                                    .option(\"es.net.http.auth.pass\",es_pass) \\\n",
        "                                                    .option(\"es.batch.size.entries\", 60000) \\\n",
        "                                                    .mode(\"overwrite\").save(index_name)\n",
        "    response_data = {'response_Code':'200','response':'Inserted Sucessfully'}\n",
        "    print(response_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xxHWntEZXn5n"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    # Configuration\n",
        "    config_file = 'config.yml'\n",
        "    with open(config_file) as f:\n",
        "        config = yaml.safe_load(f)\n",
        "    oracle_config = config['CONFIG+FILE']\n",
        "    es_config = config['CONFIG+FILE']\n",
        "    es_config['index_name'] = 'YOUR_INDEX_NAME'\n",
        "\n",
        "    spark = createSparkSession()\n",
        "    df = readFromElasticSearch(spark,es_config['index_name'])\n",
        "    df.take(1)\n",
        "#     writeToElasticSearch(df,es_config)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "read data from es.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}